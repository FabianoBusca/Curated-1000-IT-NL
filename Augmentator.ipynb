{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Generate the missing data\n",
    "\n",
    "The dataset is still missing 19 sentences reflecting Double Negation and 113 for the Diminutives and Augmentatives. "
   ],
   "id": "536969a7de81e051"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T10:39:27.481894Z",
     "start_time": "2024-12-02T10:39:27.477687Z"
    }
   },
   "cell_type": "code",
   "source": "# %pip install bert_score",
   "id": "1b21ea1444216f98",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-02T10:39:44.836135Z",
     "start_time": "2024-12-02T10:39:27.484368Z"
    }
   },
   "source": [
    "import string\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from bert_score import score\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "def has_double_negation(sentence):\n",
    "    \"\"\"Check if the sentence contains double negation.\"\"\"\n",
    "    negative_words = [\"niente\", \"nessuno\", \"nessuna\", \"nessun\", \"nulla\"]\n",
    "    words = sentence.lower().split()\n",
    "    return words.count(\"non\") > 1 or \"non\" in words and any(word in words for word in negative_words)\n",
    "\n",
    "with open(\"./Datasets/Diminutives-Augmentatives.txt\", 'r', encoding='utf-8') as file:\n",
    "    diminutives_augmentatives = [line.strip() for line in file]\n",
    "\n",
    "def has_diminutives_or_augmentatives(sentence):\n",
    "    \"\"\"Check if the sentence contains diminutives or augmentatives.\"\"\"\n",
    "    suffixes = [\"ino\", \"ina\", \"etto\", \"etta\", \"accio\", \"accia\", \"one\", \"ona\"]\n",
    "    sentence_no_punct = sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    return any(word for word in sentence_no_punct.split() if word in diminutives_augmentatives)\n",
    "\n",
    "# Load the NLLB model and tokenizer from Hugging Face\n",
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "source_lang_code = \"ita_Latn\"  # Italian\n",
    "target_lang_code = \"nld_Latn\"  # Dutch\n",
    "\n",
    "def nllb_model(italian_sentence, dutch_sentence):\n",
    "    input_sentence = f\">>{source_lang_code}<< {italian_sentence}\"\n",
    "\n",
    "    inputs = tokenizer(input_sentence, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Generate translation\n",
    "    with torch.no_grad():\n",
    "        translated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.convert_tokens_to_ids(f\">>{target_lang_code}<<\"))\n",
    "    translated_sentence = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "    if translated_sentence == dutch_sentence:\n",
    "        return 1.0  # Perfect match\n",
    "    else:\n",
    "        return calculate_similarity(translated_sentence, dutch_sentence)\n",
    "\n",
    "# Calculate similarity using BERTScore\n",
    "def calculate_similarity(translated, reference):\n",
    "    P, R, F1 = score([translated], [reference], lang=\"nl\")\n",
    "    return F1.item()\n",
    "\n",
    "def evaluate_llm_output(llm_response_path, verify_phenomenon, prompt_type=\"zero-shot\"):\n",
    "    \"\"\"\n",
    "    Evaluates the LLM output based on linguistic validity, diversity, and translation quality.\n",
    "    \n",
    "    Parameters:\n",
    "        llm_response_path (str): Path to the text file containing the output from the LLM, expected to be a JSON list or a list of JSON objects.\n",
    "        verify_phenomenon (function): A function that takes a sentence and checks if it reflects the target phenomenon.\n",
    "        prompt_type (str): The type of prompt used for the LLM response (default: \"zero-shot\").\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with evaluation metrics:\n",
    "            - valid_sentences: List of valid sentences with translations.\n",
    "            - linguistic_validity: Percentage of sentences valid for the phenomenon.\n",
    "            - diversity: Metric for diversity (e.g., number of unique words/total words ratio).\n",
    "            - total_sentences: Total number of sentences processed.\n",
    "            - avg_translation_quality: Average quality score of translations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(llm_response_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            llm_response = file.read()\n",
    "        \n",
    "        # Extract JSON-like content from the response\n",
    "        json_pattern = re.search(r\"\\[.*\\]\", llm_response, re.DOTALL)\n",
    "        if json_pattern:\n",
    "            data = json.loads(json_pattern.group(0))  # Parse JSON content\n",
    "        else:\n",
    "            return {\"valid_sentences\": [], \"linguistic_validity\": 0, \"diversity\": 0, \"total_sentences\": 0, \"avg_translation_quality\": 0}\n",
    "        \n",
    "        # Ensure it's a list of JSON objects\n",
    "        if not isinstance(data, list):\n",
    "            raise ValueError(\"The LLM response is not a JSON list.\")\n",
    "        \n",
    "        # Extract sentences and translations\n",
    "        sentences_with_translations = []\n",
    "        for item in data:\n",
    "            if \"Italian\" in item and \"Dutch\" in item:\n",
    "                sentences_with_translations.append((item[\"Italian\"], item[\"Dutch\"]))\n",
    "        \n",
    "        # Initialize metrics\n",
    "        valid_sentences = []\n",
    "        all_words = []\n",
    "        total_quality_score = 0\n",
    "        quality_scores_count = 0\n",
    "\n",
    "        # Evaluate sentences\n",
    "        for italian, dutch in sentences_with_translations:\n",
    "            if verify_phenomenon(italian):\n",
    "                valid_sentences.append({\"Italian\": italian, \"Dutch\": dutch})\n",
    "                all_words.extend(italian.split())  # Collect words for diversity\n",
    "\n",
    "                # Use NLLB model to evaluate translation quality\n",
    "                quality_score = nllb_model(italian, dutch)\n",
    "                total_quality_score += quality_score\n",
    "                quality_scores_count += 1\n",
    "        \n",
    "        # Calculate metrics\n",
    "        total_sentences = len(sentences_with_translations)\n",
    "        linguistic_validity = len(valid_sentences) / total_sentences if total_sentences > 0 else 0\n",
    "        unique_words = len(set(all_words))\n",
    "        diversity = unique_words / len(all_words) if all_words else 0\n",
    "        avg_translation_quality = total_quality_score / quality_scores_count if quality_scores_count > 0 else 0\n",
    "\n",
    "        # Return metrics\n",
    "        return {\n",
    "            \"prompt_type\": prompt_type,\n",
    "            \"total_sentences\": total_sentences,\n",
    "            \"valid_sentences\": len(valid_sentences),\n",
    "            \"linguistic_validity\": round(linguistic_validity * 100, 2),\n",
    "            \"diversity\": round(diversity * 100, 2),\n",
    "            \"avg_translation_quality\": round(avg_translation_quality * 100, 2),\n",
    "        }, valid_sentences\n",
    "\n",
    "    except (json.JSONDecodeError, ValueError) as e:\n",
    "        raise ValueError(f\"An error occurred while processing the LLM response: {e}\")\n",
    "    \n",
    "def plot_metrics(metrics_data):\n",
    "    metrics = ['total_sentences', 'valid_sentences', 'linguistic_validity', 'avg_translation_quality', 'diversity']\n",
    "    num_objects = len(metrics_data)\n",
    "\n",
    "    values = [[obj[metric] for metric in metrics] for obj in metrics_data]\n",
    "    labels = [obj['prompt_type'] for obj in metrics_data]\n",
    "\n",
    "    values = np.array(values)\n",
    "\n",
    "    x = np.arange(num_objects)\n",
    "    width = 0.15\n",
    "    colors = sns.color_palette(\"rainbow\", 15)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    for i in range(5):\n",
    "        ax.bar(x + i * width, values[:, i], width, label=metrics[i].replace('_', ' ').title(), color=colors[i * 3])\n",
    "\n",
    "    ax.set_xlabel('Prompt Type')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_title('Metrics for Each Prompt Type')\n",
    "    ax.set_xticks(x + width * 2.5)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Subject Omission",
   "id": "8c7b65711dfa358b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Zero-shot Prompt\n",
    "\n",
    "\"Generate 20 Italian sentence and Their Dutch translation that reflect the linguistic phenomena of Double Negation. Give your output in a list of json objects with the fields 'Italian' and 'Dutch'.\""
   ],
   "id": "20302447a44b2290"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-02T10:39:44.841675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dn_zero_shot_metrics, dn_zero_shot_sentences = evaluate_llm_output('LLM-Responses/Double-Negation/DN-Zero-Shot.txt', verify_phenomenon=has_double_negation, prompt_type=\"zero-shot\")\n",
    "dn_zero_shot_metrics"
   ],
   "id": "7e832a2659f0d999",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## One-shot Prompt\n",
    "\n",
    "Generate 20 Italian sentences and Their Dutch translation that reflect the linguistic phenomena of Double Negation like 'Non ho mangiato nulla' : 'Ik heb niets gegeten'. Give your output in a list of json objects with the fields 'Italian' and 'Dutch'."
   ],
   "id": "476e71de33e52ff4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ba8dca634fd0edfd"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "dn_one_shot_metrics, dn_one_shot_sentences = evaluate_llm_output('LLM-Responses/Double-Negation/DN-One-Shot.txt', verify_phenomenon=has_double_negation, prompt_type=\"one-shot\")\n",
    "dn_one_shot_metrics"
   ],
   "id": "8b2fb2834364aa9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Zero-shot prompt with explanation\n",
    "\n",
    "Generate 20 Italian sentences and Their Dutch translation that reflect the linguistic phenomena of Double Negation. Double Negation occurs when a sentence has both the negative particle 'non' and another negative word between 'niente', 'nessuno', 'nessuna', 'nessun', 'nulla'. Give your output in a list of json objects with the fields 'Italian' and 'Dutch'."
   ],
   "id": "9450821709f8de2b"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "dn_zero_shot_exp_metrics, dn_zero_shot_exp_sentences = evaluate_llm_output(\n",
    "    'LLM-Responses/Double-Negation/DN-Zero-Shot-Exp.txt', verify_phenomenon=has_double_negation, prompt_type=\"zero-shot-explanation\")\n",
    "dn_zero_shot_exp_metrics"
   ],
   "id": "db64f847edeb99c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## One-shot prompt with explanation\n",
    "\n",
    "Generate 20 Italian sentences and Their Dutch translation that reflect the linguistic phenomena of Double Negation. Double Negation occurs when a sentence has both the negative particle 'non' and another negative word between 'niente', 'nessuno', 'nessuna', 'nessun', 'nulla' like 'Non ho mangiato nulla' : 'Ik heb niets gegeten'. Give your output in a list of json objects with the fields 'Italian' and 'Dutch'."
   ],
   "id": "fba84c9de24813da"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "dn_one_shot_exp_metrics, dn_one_shot_exp_sentences = evaluate_llm_output(\n",
    "    'LLM-Responses/Double-Negation/DN-One-Shot-Exp.txt', verify_phenomenon=has_double_negation, prompt_type=\"one-shot-explanation\")\n",
    "dn_one_shot_exp_metrics"
   ],
   "id": "c37254043c97f256",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot the metrics",
   "id": "ac8a3b7ed62473c9"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "plot_metrics([dn_zero_shot_metrics, dn_one_shot_metrics, dn_zero_shot_exp_metrics, dn_one_shot_exp_metrics])",
   "id": "26bef77c3b9f6b59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Zero shot prompt with explanation has the highest average translation quality and diversity. We will use this prompt to generate more sentences.",
   "id": "16d491fed42a46c8"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "len(dn_zero_shot_exp_sentences)",
   "id": "e6274d7d935ebab0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "additional_dn_zero_shot_exp_metrics, additional_dn_zero_shot_exp_sentences = evaluate_llm_output(\n",
    "    'LLM-Responses/Double-Negation/DN-Zero-Shot-Exp-Additional.txt', verify_phenomenon=has_double_negation, prompt_type=\"zero-shot-explanation\")\n",
    "additional_dn_zero_shot_exp_metrics"
   ],
   "id": "8eed9be8e53832a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "generated_dn_sentences = dn_zero_shot_exp_sentences + additional_dn_zero_shot_exp_sentences\n",
    "\n",
    "with open(\"./Datasets/Double-Negation-Generated-IT-NL.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Italian\\tDutch\\n\")\n",
    "    for item in generated_dn_sentences:\n",
    "        f.write(f\"{item['Italian']}\\t{item['Dutch']}\\n\")"
   ],
   "id": "3d5bc721b8552d19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Diminutives and Augmentatives",
   "id": "da6c0cf0f86a8714"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Zero-shot Prompt\n",
    "\n",
    "Generate 20 Italian sentences and their Dutch translation that reflect the linguistic use of diminutives and augmentatives. Give your output in a list of json objects with the fields 'Italian' and 'Dutch'."
   ],
   "id": "8921f71794687901"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "da_zero_shot_metrics, da_zero_shot_sentences = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-Zero-Shot.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"zero-shot\")\n",
    "da_zero_shot_metrics"
   ],
   "id": "8f8c6e06dfe69575",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## One-shot Prompt\n",
    "\n",
    "Generate 20 Italian sentences and their Dutch translation that reflect the linguistic use of diminutives and augmentatives, like 'Ho un gattino' : 'Ik heb een katje'. Give your output in a list of json objects with the fields 'Italian' and 'Dutch'."
   ],
   "id": "a86cced7a2f28eda"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "da_one_shot_metrics, da_one_shot_sentences = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-One-Shot.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"one-shot\")\n",
    "da_one_shot_metrics"
   ],
   "id": "f967d226721f1eca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Zero-shot prompt with explanation\n",
    "\n",
    "Generate 20 Italian sentences and their Dutch translation that reflect the linguistic use of diminutives and augmentatives. Diminutives and augmentatives in Italian are formed with the use of the suffixes 'ino', 'ina', 'etto', 'etta', 'one', 'ona', 'accio', 'accia'. Give your output in a list of json objects with the fields 'Italian' and 'Dutch'."
   ],
   "id": "3384538c5ea8ce5"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "da_zero_shot_exp_metrics, da_zero_shot_exp_sentences = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-Zero-Shot-Exp.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"zero-shot-explanation\")\n",
    "da_zero_shot_exp_metrics"
   ],
   "id": "7ef8787907441aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## One-shot prompt with explanation\n",
    "\n",
    "Generate 20 Italian sentences and their Dutch translation that reflect the linguistic use of diminutives and augmentatives. Diminutives and augmentatives in Italian are formed with the use of the suffixes 'ino', 'ina', 'etto', 'etta', 'one', 'ona', 'accio', 'accia', like 'Ho un gattino' : 'Ik heb een katje'. Give your output in a list of json objects with the fields 'Italian' and 'Dutch'."
   ],
   "id": "3df54b8a1bc554d6"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "da_one_shot_exp_metrics, da_one_shot_exp_sentences = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-One-Shot-exp.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"one-shot-explanation\")\n",
    "da_one_shot_exp_metrics"
   ],
   "id": "66a39b2c62b0bfcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot the metrics",
   "id": "cab015706db1752"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "plot_metrics([da_zero_shot_metrics, da_one_shot_metrics, da_zero_shot_exp_metrics, da_one_shot_exp_metrics])",
   "id": "1a975cc61c86dee1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The zero-shot prompt achieved the highest average translation quality and diversity, which might be due to its very low linguistic validity, with only 4 valid sentences. Therefore, we will use the one-shot prompt with explanation, which has an average translation quality just 1.2% lower and still maintains 75% diversity.",
   "id": "5549bc55e688f509"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "len(da_one_shot_exp_sentences)",
   "id": "717a4e95895bd0d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "additional_da_one_shot_exp_metrics, additional_da_one_shot_exp_sentences = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-One-Shot-Exp-Additional.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"one-shot-explanation\")\n",
    "additional_da_one_shot_exp_metrics"
   ],
   "id": "df75ec91fb5578c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "additional_da_one_shot_exp_metrics1, additional_da_one_shot_exp_sentences1 = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-One-Shot-Exp-Additional1.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"one-shot-explanation\")\n",
    "additional_da_one_shot_exp_metrics1"
   ],
   "id": "93f30dd5406fc9a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "additional_da_one_shot_exp_metrics2, additional_da_one_shot_exp_sentences2 = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-One-Shot-Exp-Additional2.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"one-shot-explanation\")\n",
    "additional_da_one_shot_exp_metrics2"
   ],
   "id": "ea2e461f78f00fb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "additional_da_one_shot_exp_metrics3, additional_da_one_shot_exp_sentences3 = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-One-Shot-Exp-Additional3.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"one-shot-explanation\")\n",
    "additional_da_one_shot_exp_metrics3"
   ],
   "id": "2c74227e34366dfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "additional_da_one_shot_exp_metrics4, additional_da_one_shot_exp_sentences4 = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-One-Shot-Exp-Additional4.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"one-shot-explanation\")\n",
    "additional_da_one_shot_exp_metrics4"
   ],
   "id": "9eb870b0ecf09fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "additional_da_one_shot_exp_metrics5, additional_da_one_shot_exp_sentences5 = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-One-Shot-Exp-Additional5.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"one-shot-explanation\")\n",
    "additional_da_one_shot_exp_metrics5"
   ],
   "id": "6fdbf7d0da429899",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "additional_da_one_shot_exp_metrics6, additional_da_one_shot_exp_sentences6 = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-One-Shot-Exp-Additional6.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"one-shot-explanation\")\n",
    "additional_da_one_shot_exp_metrics6"
   ],
   "id": "e9cf82ed4efc898f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "additional_da_one_shot_exp_metrics7, additional_da_one_shot_exp_sentences7 = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-One-Shot-Exp-Additional7.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"one-shot-explanation\")\n",
    "additional_da_one_shot_exp_metrics7"
   ],
   "id": "e504f123b98f130e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "additional_da_one_shot_exp_metrics8, additional_da_one_shot_exp_sentences8 = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-One-Shot-Exp-Additional8.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"one-shot-explanation\")\n",
    "additional_da_one_shot_exp_metrics8"
   ],
   "id": "c0c863eebc6daf7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "additional_da_one_shot_exp_metrics9, additional_da_one_shot_exp_sentences9 = evaluate_llm_output(\n",
    "    'LLM-Responses/Diminutives-Augmentatives/DA-One-Shot-Exp-Additional9.txt', verify_phenomenon=has_diminutives_or_augmentatives, prompt_type=\"one-shot-explanation\")\n",
    "additional_da_one_shot_exp_metrics9"
   ],
   "id": "b6462214443db885",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "generated_da_sentences = additional_da_one_shot_exp_sentences + additional_da_one_shot_exp_sentences1 + additional_da_one_shot_exp_sentences2 + additional_da_one_shot_exp_sentences3 + additional_da_one_shot_exp_sentences4 + additional_da_one_shot_exp_sentences5 + additional_da_one_shot_exp_sentences6 + additional_da_one_shot_exp_sentences7 + additional_da_one_shot_exp_sentences8 + additional_da_one_shot_exp_sentences9\n",
    "\n",
    "with open(\"./Datasets/Diminutives-Augmentatives-Generated-IT-NL.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Italian\\tDutch\\n\")\n",
    "    for item in generated_da_sentences:\n",
    "        f.write(f\"{item['Italian']}\\t{item['Dutch']}\\n\")"
   ],
   "id": "b25b6406cd40b471",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
